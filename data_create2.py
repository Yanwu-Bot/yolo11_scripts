import os
import cv2
import numpy as np
from ultralytics import YOLO
from tqdm import tqdm
from sklearn.model_selection import train_test_split
import tkinter as tk
from tkinter import simpledialog
from matplotlib import rcParams #å­—ä½“
rcParams['font.family'] = 'SimHei'

# ============================ æ ¸å¿ƒé…ç½® ============================
VIDEO_DIR = "video_origin\data_video"          
LABEL_SAVE_DIR = "video_labels"  
SAVE_DIR = "video_dataset"     
SAMPLE_FPS = 10                       
WINDOW_SIZE = 6                      
STEP = 2                              
# COCO 17ä¸ªå…³é”®ç‚¹çš„æ ‡å‡†ç´¢å¼•+åç§°ï¼ˆç²¾å‡†å¯¹åº”ï¼‰
COCO_KEYPOINTS = [
    "nose", "left_eye", "right_eye", "left_ear", "right_ear",
    "left_shoulder", "right_shoulder", "left_elbow", "right_elbow",
    "left_wrist", "right_wrist", "left_hip", "right_hip",
    "left_knee", "right_knee", "left_ankle", "right_ankle"
]
KEY_JOINTS = list(range(17))  # ä¿æŒ17ä¸ªå…³é”®ç‚¹ï¼Œä½†ç»˜åˆ¶æ—¶æŒ‰æ ‡å‡†ç´¢å¼•æ¥
CONF_THRESHOLD = 0.5                  
# å…³é”®ä¿®å¤ï¼šå…ˆæå–åŸå§‹åæ ‡ï¼Œå½’ä¸€åŒ–åªç”¨äºæ¨¡å‹è¾“å…¥ï¼Œç»˜åˆ¶ç”¨åŸå§‹åæ ‡
NORMALIZE = True                      
TEST_SIZE = 0.2                       
RANDOM_SEED = 42                      
# =================================================================

# åˆå§‹åŒ–YOLO11-Poseæ¨¡å‹ï¼ˆç¡®ä¿åŠ è½½å®˜æ–¹æƒé‡ï¼Œå…³é”®ç‚¹æ›´å‡†ï¼‰
model = YOLO("weights\yolo11l-pose.pt")

# åˆ›å»ºç›®å½•
os.makedirs(VIDEO_DIR, exist_ok=True)
os.makedirs(LABEL_SAVE_DIR, exist_ok=True)
os.makedirs(SAVE_DIR, exist_ok=True)

# -------------------------- ä¿®å¤ï¼šç²¾å‡†æå–å…³é”®ç‚¹ï¼ˆåŸå§‹+å½’ä¸€åŒ–ï¼‰ --------------------------
def extract_pose_from_frame(frame, return_original=True):
    """
    æå–17ä¸ªå…³é”®ç‚¹çš„åŸå§‹åæ ‡+å½’ä¸€åŒ–åæ ‡
    :param frame: åŸå§‹å¸§
    :param return_original: æ˜¯å¦è¿”å›åŸå§‹åƒç´ åæ ‡
    :return: norm_poseï¼ˆå½’ä¸€åŒ–ï¼‰, original_poseï¼ˆåŸå§‹åƒç´ åæ ‡ï¼‰
    """
    h, w = frame.shape[:2]  #è·å–å¸§é«˜å®½
    results = model(frame, conf=CONF_THRESHOLD)
    
    # åˆå§‹åŒ–åŸå§‹åæ ‡å’Œå½’ä¸€åŒ–åæ ‡
    original_pose = np.zeros((17, 2))  # (17, 2) åŸå§‹åƒç´ åæ ‡
    norm_pose = np.zeros((17, 2))      # (17, 2) å½’ä¸€åŒ–åæ ‡
    
    if len(results[0].keypoints) > 0:
        # æå–YOLOè¾“å‡ºçš„å…³é”®ç‚¹ï¼ˆx,y,confï¼‰
        kpts = results[0].keypoints.data[0].cpu().numpy()  # (17, 3)
        for i in range(17):
            x, y, conf = kpts[i]
            if conf >= CONF_THRESHOLD:
                # åŸå§‹åƒç´ åæ ‡
                original_pose[i] = [x, y]
                # å½’ä¸€åŒ–åæ ‡ï¼ˆ0-1ï¼‰
                norm_pose[i] = [x/w, y/h]
    
    # å±•å¹³è¿”å›
    norm_pose_flat = norm_pose.flatten()  # (34,)
    original_pose_flat = original_pose.flatten()  # (34,)
    
    if return_original:
        return norm_pose_flat, original_pose_flat
    else:
        return norm_pose_flat

# -------------------------- ä¿®å¤ï¼šç²¾å‡†ç»˜åˆ¶å…³é”®ç‚¹ --------------------------
def draw_keypoints(frame, original_pose, thickness=2):
    """
    åœ¨åŸå§‹å¸§ä¸Šç»˜åˆ¶ç²¾å‡†çš„å…³é”®ç‚¹+éª¨éª¼è¿çº¿
    :param frame: åŸå§‹å¸§
    :param original_pose: åŸå§‹åƒç´ åæ ‡çš„å…³é”®ç‚¹ (34,) â†’ å±•å¹³çš„(17,2)
    :return: å¸¦å…³é”®ç‚¹çš„å¸§
    """
    frame_copy = frame.copy()
    kpts = original_pose.reshape(-1, 2)  # é‡æ–°å˜æˆï¼ˆ17ï¼Œ2ï¼‰
    
    # COCOå…³é”®ç‚¹éª¨éª¼è¿çº¿ï¼ˆæŒ‰äººä½“ç»“æ„ï¼‰
    skeleton = [
        (0, 1), (0, 2), (1, 3), (2, 4),  # å¤´éƒ¨
        (5, 6), (5, 7), (7, 9), (6, 8), (8, 10),  # ä¸Šè‚¢
        (11, 12), (11, 13), (13, 15), (12, 14), (14, 16)  # ä¸‹è‚¢
    ]
    
    # 1. ç»˜åˆ¶éª¨éª¼è¿çº¿
    for (i, j) in skeleton:
        x1, y1 = int(kpts[i][0]), int(kpts[i][1])
        x2, y2 = int(kpts[j][0]), int(kpts[j][1])
        # åªç»˜åˆ¶æœ‰æ•ˆå…³é”®ç‚¹ï¼ˆåæ ‡>0ï¼‰
        if x1 > 0 and y1 > 0 and x2 > 0 and y2 > 0:
            cv2.line(frame_copy, (x1, y1), (x2, y2), (0, 255, 0), thickness)
    
    # 2. ç»˜åˆ¶å…³é”®ç‚¹ï¼ˆä¸åŒå…³èŠ‚ä¸åŒé¢œè‰²ï¼‰
    colors = [
        (0, 0, 255),  # å¤´éƒ¨ï¼ˆçº¢ï¼‰
        (255, 0, 0),  # ä¸Šè‚¢ï¼ˆè“ï¼‰
        (0, 255, 0)   # ä¸‹è‚¢ï¼ˆç»¿ï¼‰
    ]
    # å¤´éƒ¨å…³é”®ç‚¹ï¼ˆ0-4ï¼‰
    for i in range(5):
        x, y = int(kpts[i][0]), int(kpts[i][1])
        if x > 0 and y > 0:
            cv2.circle(frame_copy, (x, y), 5, colors[0], -1)
    # ä¸Šè‚¢å…³é”®ç‚¹ï¼ˆ5-10ï¼‰
    for i in range(5, 11):
        x, y = int(kpts[i][0]), int(kpts[i][1])
        if x > 0 and y > 0:
            cv2.circle(frame_copy, (x, y), 5, colors[1], -1)
    # ä¸‹è‚¢å…³é”®ç‚¹ï¼ˆ11-16ï¼‰
    for i in range(11, 17):
        x, y = int(kpts[i][0]), int(kpts[i][1])
        if x > 0 and y > 0:
            cv2.circle(frame_copy, (x, y), 5, colors[2], -1)
    
    return frame_copy

# -------------------------- ä¿®å¤ï¼šæ‰‹åŠ¨æ ‡æ³¨ï¼ˆç²¾å‡†å…³é”®ç‚¹å¯è§†åŒ–ï¼‰ --------------------------
def manual_label_frames(video_path, norm_pose_seq, original_pose_seq, frame_list):
    """
    å¯è§†åŒ–å¸¦ç²¾å‡†å…³é”®ç‚¹çš„å¸§ï¼Œæ‰‹åŠ¨æ ‡æ³¨0/1ï¼ˆä¼˜åŒ–ï¼šé”®ç›˜ç›´æ¥è¾“å…¥ï¼Œæ— éœ€ç‚¹å‡»è¾“å…¥æ¡†ï¼‰
    :param video_path: è§†é¢‘è·¯å¾„
    :param norm_pose_seq: å½’ä¸€åŒ–å§¿æ€åºåˆ— (å¸§æ•°, 34)
    :param original_pose_seq: åŸå§‹åƒç´ åæ ‡å§¿æ€åºåˆ— (å¸§æ•°, 34)
    :param frame_list: åŸå§‹å¸§åˆ—è¡¨
    :return: labels (å¸§æ•°,)
    """
    video_name = os.path.basename(video_path).split('.')[0]
    label_save_path = os.path.join(LABEL_SAVE_DIR, f"{video_name}.txt")
    
    # åŠ è½½å·²æœ‰æ ‡æ³¨
    if os.path.exists(label_save_path):
        print(f"åŠ è½½å·²æœ‰æ ‡æ³¨ï¼š{video_name}.txt")
        labels = np.loadtxt(label_save_path).astype(int)
        return labels
    
    labels = []
    total_frames = len(frame_list)
    
    # ç§»é™¤tkinterä¾èµ–ï¼ˆæ”¹ç”¨é”®ç›˜è¾“å…¥ï¼‰
    print(f"\n========== æ ‡æ³¨è§†é¢‘ï¼š{video_name} ==========")
    print("      æ ‡æ³¨æ“ä½œè¯´æ˜ï¼š      ")
    print("   æŒ‰ 0 é”® â†’ æ ‡æ³¨ä¸ºæ­£å¸¸")
    print("   æŒ‰ 1 é”® â†’ æ ‡æ³¨ä¸ºå¼‚å¸¸")
    print("   æŒ‰ ESC é”® â†’ è·³è¿‡å‰©ä½™å¸§ï¼ˆé»˜è®¤æ ‡0ï¼‰")
    print("   æŒ‰ ç©ºæ ¼é”® â†’ æš‚åœ/ç»§ç»­æ ‡æ³¨ï¼ˆå¯é€‰ï¼‰")
    print("==============================================")
    
    # åˆ›å»ºæ˜¾ç¤ºçª—å£ï¼ˆå›ºå®šåç§°ï¼Œé¿å…å¤šçª—å£ï¼‰
    cv2.namedWindow(f"ç²¾å‡†å…³é”®ç‚¹æ ‡æ³¨ - {video_name}", cv2.WINDOW_NORMAL)
    cv2.resizeWindow(f"ç²¾å‡†å…³é”®ç‚¹æ ‡æ³¨ - {video_name}", 800, 600)
    
    pause = False  # æš‚åœæ ‡å¿—
    for i in range(total_frames):
        if pause:
            # æš‚åœçŠ¶æ€ï¼šç­‰å¾…ç©ºæ ¼é”®ç»§ç»­
            while True:
                key = cv2.waitKey(1) & 0xFF
                if key == 32:  # ç©ºæ ¼é”®ç»§ç»­
                    pause = False
                    break
                elif key == 27:  # ESCé€€å‡º
                    print(" ESCè·³è¿‡ï¼Œå‰©ä½™å¸§æ ‡ä¸º0")
                    labels.extend([0] * (total_frames - len(labels)))
                    cv2.destroyAllWindows()
                    break
            if key == 27:
                break
        
        frame = frame_list[i]
        original_pose = original_pose_seq[i]
        
        # ç»˜åˆ¶ç²¾å‡†çš„å…³é”®ç‚¹+éª¨éª¼
        frame_with_kpts = draw_keypoints(frame, original_pose)
        # ç¼©æ”¾çª—å£ï¼ˆé€‚é…å±å¹•ï¼‰
        h, w = frame_with_kpts.shape[:2]
        #ç¼©æ”¾æ¯”ä¾‹
        scale = min(1200/w, 900/h) 
        display_frame = cv2.resize(frame_with_kpts, (int(w*scale), int(h*scale)))
        
        # æ˜¾ç¤ºå¸§ä¿¡æ¯å’Œæ“ä½œæç¤º
        cv2.putText(display_frame, f"Frame {i+1}/{total_frames}", (10, 30),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
        cv2.putText(display_frame, "0=normal  1=abnoraml  ESC=skip  space=stop", (10, 70),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
        
        # æ˜¾ç¤ºå½“å‰å¸§
        cv2.imshow(f"å…³é”®ç‚¹æ ‡æ³¨ - {video_name}", display_frame)
        
        # ç­‰å¾…é”®ç›˜è¾“å…¥ï¼ˆæ— è¶…æ—¶ï¼Œç›´åˆ°æŒ‰ä¸‹æœ‰æ•ˆé”®ï¼‰
        while True:
            key = cv2.waitKey(0) & 0xFF  # 0è¡¨ç¤ºæ— é™ç­‰å¾…è¾“å…¥
            if key == 48:  # æ•°å­—é”®0
                labels.append(0)
                print(f"å¸§{i+1}/{total_frames} â†’ æ ‡æ³¨ä¸ºæ­£å¸¸(0)")
                break
            elif key == 49:  # æ•°å­—é”®1
                labels.append(1)
                print(f"å¸§{i+1}/{total_frames} â†’ æ ‡æ³¨ä¸ºå¼‚å¸¸(1)")
                break
            elif key == 27:  # ESCé”®
                print(" ESCè·³è¿‡ï¼Œå‰©ä½™å¸§æ ‡ä¸º0")
                labels.extend([0] * (total_frames - len(labels)))
                cv2.destroyAllWindows()
                labels = np.array(labels, dtype=int)
                np.savetxt(label_save_path, labels, fmt="%d")
                print(f"âœ… æ ‡æ³¨å®Œæˆï¼š{label_save_path} | æ­£å¸¸={np.sum(labels==0)}, å¼‚å¸¸={np.sum(labels==1)}")
                return labels
            elif key == 32:  # ç©ºæ ¼é”®
                pause = True
                print(f"å¸§{i+1}/{total_frames} â†’ å·²æš‚åœï¼ˆæŒ‰ç©ºæ ¼é”®ç»§ç»­ï¼‰")
                break
            else:
                print(f" æ— æ•ˆæŒ‰é”®ï¼è¯·æŒ‰ 0/1/ESC/ç©ºæ ¼ï¼Œå½“å‰æŒ‰é”®ï¼š{key}")
                continue
    
    # å…³é—­çª—å£
    cv2.destroyAllWindows()
    
    # è½¬æ¢ä¸ºæ•°ç»„å¹¶ä¿å­˜
    labels = np.array(labels, dtype=int)
    np.savetxt(label_save_path, labels, fmt="%d")
    print(f" æ ‡æ³¨å®Œæˆï¼š{label_save_path} | æ­£å¸¸å¸§æ•°={np.sum(labels==0)}, å¼‚å¸¸å¸§æ•°={np.sum(labels==1)}")
    
    return labels

# -------------------------- ä¿®å¤ï¼šè§†é¢‘å¤„ç†æµç¨‹ï¼ˆä¿å­˜åŸå§‹å…³é”®ç‚¹ï¼‰ --------------------------
def process_single_video(video_path):
    """å¤„ç†å•è§†é¢‘ï¼šæŠ½å¸§â†’æç²¾å‡†å…³é”®ç‚¹â†’æ‰‹åŠ¨æ ‡æ³¨"""
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        print(f"æ— æ³•æ‰“å¼€è§†é¢‘ï¼š{video_path}")
        return None, None
    
    video_fps = cap.get(cv2.CAP_PROP_FPS)
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    #é‡‡æ ·å¸§æ•°ï¼Œè§†é¢‘å˜ä¸ºSAMPLE_FPSå¸§
    frame_interval = max(1, int(video_fps / SAMPLE_FPS))
    
    # ä¿å­˜ä¸‰ç±»æ•°æ®ï¼šå½’ä¸€åŒ–å§¿æ€ã€åŸå§‹å§¿æ€ã€åŸå§‹å¸§
    norm_pose_list = []
    original_pose_list = []
    frame_list = []
    
    for frame_idx in range(0, total_frames, frame_interval):
        #è½¬ç§»åˆ°ç´¢å¼•å¸§
        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)
        ret, frame = cap.read()
        if not ret:
            break
        # æå–ç²¾å‡†çš„å…³é”®ç‚¹ï¼ˆåŸå§‹+å½’ä¸€åŒ–ï¼‰
        norm_pose, original_pose = extract_pose_from_frame(frame)
        norm_pose_list.append(norm_pose)
        original_pose_list.append(original_pose)
        frame_list.append(frame)
    
    cap.release()
    
    if len(norm_pose_list) < WINDOW_SIZE:
        print(f"å¸§æ•°ä¸è¶³ï¼š{len(norm_pose_list)} < {WINDOW_SIZE}")
        return None, None
    
    # é¢„å¤„ç†å½’ä¸€åŒ–å§¿æ€ï¼ˆç”¨äºæ¨¡å‹è¾“å…¥ï¼‰
    norm_pose_seq = np.array(norm_pose_list)
    original_pose_seq = np.array(original_pose_list)
    
    # æ‰‹åŠ¨æ ‡æ³¨ï¼ˆç”¨åŸå§‹å…³é”®ç‚¹ç»˜åˆ¶ï¼‰
    labels = manual_label_frames(video_path, norm_pose_seq, original_pose_seq, frame_list)
    
    # æ»‘åŠ¨çª—å£åˆ‡åˆ†ï¼ˆç”¨å½’ä¸€åŒ–å§¿æ€ï¼‰
    X_video, y_video = sliding_window_split(norm_pose_seq, labels)
    return X_video, y_video

def preprocess_pose_sequence(pose_seq):
    """é¢„å¤„ç†å½’ä¸€åŒ–å§¿æ€åºåˆ—ï¼ˆå¡«å……ç¼ºå¤±å€¼ï¼‰"""
    processed_seq = pose_seq.copy()
    zero_frames = np.all(processed_seq == 0, axis=1)
    for i in range(len(processed_seq)):
        if zero_frames[i]:
            neighbors = []
            if i > 0 and not zero_frames[i-1]:
                neighbors.append(processed_seq[i-1])
            if i < len(processed_seq)-1 and not zero_frames[i+1]:
                neighbors.append(processed_seq[i+1])
            if neighbors:
                processed_seq[i] = np.mean(neighbors, axis=0)
            else:
                non_zero = processed_seq[~zero_frames]
                if len(non_zero) > 0:
                    processed_seq[i] = np.mean(non_zero, axis=0)
    return processed_seq

def sliding_window_split(pose_seq, labels=None):
    """æ»‘åŠ¨çª—å£åˆ‡åˆ†"""
    X, y = [], []
    #æ»‘åŠ¨çª—å£ï¼ŒSTEPä¸ºæ»‘åŠ¨æ­¥é•¿
    for i in range(0, len(pose_seq) - WINDOW_SIZE + 1, STEP):
        window = pose_seq[i:i+WINDOW_SIZE]
        X.append(window)
        if labels is not None:
            y.append(labels[i+WINDOW_SIZE-1])
    X = np.array(X)
    y = np.array(y) if labels is not None else None
    return X, y

def print_dataset_info(X_train, y_train, X_test, y_test):
    """æ‰“å°æ•°æ®é›†ä¿¡æ¯"""
    print("\n==================== æ•°æ®é›†ä¿¡æ¯ ====================")
    print(f"ç‰¹å¾ç»´åº¦ï¼š17å…³èŠ‚Ã—2åæ ‡=34ç»´ï¼ˆå½’ä¸€åŒ–ï¼‰")
    print(f"æ—¶é—´æ­¥é•¿ï¼š{WINDOW_SIZE}å¸§")
    print(f"\nè®­ç»ƒé›†ï¼šæ€»æ•°={len(X_train)} | æ­£å¸¸={np.sum(y_train==0)} | å¼‚å¸¸={np.sum(y_train==1)}")
    print(f"æµ‹è¯•é›†ï¼šæ€»æ•°={len(X_test)} | æ­£å¸¸={np.sum(y_test==0)} | å¼‚å¸¸={np.sum(y_test==1)}")
    print("====================================================")

def main():
    video_ext = ('.mp4', '.avi', '.mov', '.mkv')
    video_files = [f for f in os.listdir(VIDEO_DIR) if f.endswith(video_ext)]
    if not video_files:
        print("âŒ æœªæ‰¾åˆ°è§†é¢‘æ–‡ä»¶ï¼")
        return
    
    all_X, all_y = [], []
    video_sample_counts = []
    for video_file in tqdm(video_files, desc="å¤„ç†è§†é¢‘"):
        video_path = os.path.join(VIDEO_DIR, video_file)
        X_video, y_video = process_single_video(video_path)
        if X_video is None:
            continue
        all_X.append(X_video)
        all_y.append(y_video)
        video_sample_counts.append(len(X_video))
    
    if not all_X:
        print("âŒ æ— æœ‰æ•ˆæ•°æ®ï¼")
        return
    
    # åˆå¹¶+åˆ’åˆ†æ•°æ®é›†
    X_total = np.concatenate(all_X, axis=0)
    y_total = np.concatenate(all_y, axis=0)
    video_indices = []
    for vid_idx, count in enumerate(video_sample_counts):
        video_indices.extend([vid_idx] * count)
    video_indices = np.array(video_indices)
    
    X_train, X_test, y_train, y_test = train_test_split(
        X_total, y_total, test_size=TEST_SIZE,
        stratify=video_indices, random_state=RANDOM_SEED
    )
    
    # ä¿å­˜æ•°æ®é›†
    np.savez(os.path.join(SAVE_DIR, "train.npz"), X=X_train, y=y_train)
    np.savez(os.path.join(SAVE_DIR, "test.npz"), X=X_test, y=y_test)
    
    # æ‰“å°ä¿¡æ¯
    print_dataset_info(X_train, y_train, X_test, y_test)
    print(f"\nâœ… æ•°æ®é›†ä¿å­˜è‡³ï¼š{SAVE_DIR}")
    print(f"ğŸ“Œ å…³é”®ç‚¹å·²ç²¾å‡†æ ¡å‡†ï¼Œæ ‡æ³¨æ ‡ç­¾ä¿å­˜è‡³ï¼š{LABEL_SAVE_DIR}")

def load_dataset():
    """åŠ è½½æ•°æ®é›†"""
    train_data = np.load(os.path.join(SAVE_DIR, "train.npz"))
    X_train = train_data["X"]
    y_train = train_data["y"]
    
    test_data = np.load(os.path.join(SAVE_DIR, "test.npz"))
    X_test = test_data["X"]
    y_test = test_data["y"]
    
    return X_train, y_train, X_test, y_test

if __name__ == "__main__":
    main()
    # éªŒè¯åŠ è½½
    X_train, y_train, X_test, y_test = load_dataset()
    print(f"\nğŸ” æ•°æ®é›†åŠ è½½éªŒè¯ï¼š")
    print(f"è®­ç»ƒé›†å½¢çŠ¶ï¼š{X_train.shape} | æ ‡ç­¾å½¢çŠ¶ï¼š{y_train.shape}")